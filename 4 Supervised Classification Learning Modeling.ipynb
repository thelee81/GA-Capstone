{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score,roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm, linear_model\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "X_st_train,X_st_test,y_st_train,y_st_test,X_train,X_test,un_X,un_y,y_train,y_test,params,estm,pred_un=[0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pipeline training data to standard scalar, selected classifiers then grid search for\n",
    "# best parameters and output confusion matrix.\n",
    "def Models_func(X_train=X_train,\n",
    "                      X_test=X_test,\n",
    "                      y_train=y_train,\n",
    "                      y_test=y_test,\n",
    "                      params={},\n",
    "                      estm='LR',\n",
    "                un_X=0,\n",
    "                un_y=0,\n",
    "                pred_un=False):\n",
    "    \n",
    "    if estm=='LR': #pipline and GridSearchCV Logistic Regression\n",
    "        model_name='    Logistic Regression '\n",
    "        pipeline = Pipeline([('scaler', StandardScaler()),('model',LogisticRegression())])\n",
    "        grid = GridSearchCV(pipeline, cv=5, n_jobs=-1, param_grid=params)\n",
    "        \n",
    "    elif estm=='KNN': #pipline and GridSearchCV KNeighbors Classifier\n",
    "        model_name='    KNN Classifier '\n",
    "        pipeline = Pipeline([('scaler', StandardScaler()),('model',KNeighborsClassifier())])\n",
    "        grid = GridSearchCV(pipeline, cv=5, n_jobs=-1, param_grid=params)\n",
    "    elif estm=='DTC': #pipline and GridSearchCV DTC Classifier\n",
    "        model_name='    Decision Tree Classifier '\n",
    "        pipeline = Pipeline([('scaler', StandardScaler()),('model',DecisionTreeClassifier())])\n",
    "        grid = GridSearchCV(pipeline, cv=5, n_jobs=-1, param_grid=params)\n",
    "    elif estm=='RFC': #pipline and Random Forrest Classifier\n",
    "        model_name='    Random Forrest Classifier '\n",
    "        pipeline = Pipeline([('scaler', StandardScaler()),('model',RandomForestClassifier())])\n",
    "        grid = GridSearchCV(pipeline, cv=5, n_jobs=-1, param_grid=params)\n",
    "    elif estm=='ETC': #pipline and Extra Tree Classifier\n",
    "        model_name='    Extra Tree Classifier '\n",
    "        pipeline = Pipeline([('scaler', StandardScaler()),('model',ExtraTreesClassifier())])\n",
    "        grid = GridSearchCV(pipeline, cv=5, n_jobs=-1, param_grid=params)\n",
    "    elif estm=='SVM': #pipline and Support Vector Machines\n",
    "        model_name='    Support Vector Machine '\n",
    "        pipeline = Pipeline([('scaler', StandardScaler()),('model',svm.SVC())])\n",
    "        grid = GridSearchCV(pipeline, cv=5, n_jobs=-1, param_grid=params)\n",
    "        \n",
    "    \n",
    "    print('################################################')\n",
    "    print('  {}'.format(model_name))\n",
    "    print('################################################')\n",
    "        \n",
    "    grid.fit(X_train, y_train) #fit to GridSearchCV \n",
    "    best_param=grid.best_estimator_.get_params()\n",
    "    print('')\n",
    "    print('Best parameters of classifier from GridSearchCV')\n",
    "    print('-----------------------------------------------------------')\n",
    "    print('')\n",
    "    for param_name in sorted(params.keys()):\n",
    "        print('%s: %r'%(param_name,best_param[param_name]))\n",
    "    predict=grid.predict(X_test)\n",
    "    score_train=grid.score(X_train, y_train)\n",
    "    # Score our model on the testing set.\n",
    "    score_test=grid.score(X_test, y_test)     \n",
    "    # Generate a confusion matrix.\n",
    "    with open ('./models/'+estm+'_model.plk','wb') as f:\n",
    "        pickle.dump(grid.best_estimator_,f)\n",
    "    cm=confusion_matrix(y_test, predict,labels=[1,2,3,4,5,6,7,8])\n",
    "    \n",
    "    cm_df = pd.DataFrame(cm, index=['Actual C1','Actual C2',\n",
    "                                    'Actual C3','Actual C4',\n",
    "                                    'Actual C5','Actual C6',\n",
    "                                    'Actual C7','Actual C8'], \n",
    "                          columns=['Predicted C1','Predicted C2',\n",
    "                                   'Predicted C3','Predicted C4',\n",
    "                                   'Predicted C5','Predicted C6',\n",
    "                                   'Actual C7','Actual C8'])\n",
    "    cr=classification_report(y_test,predict)\n",
    "    accu = round(accuracy_score(y_test,predict)*100,2)\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_lb = lb.transform(y_test)\n",
    "    y_pred_lb = lb.transform(predict)\n",
    "    ras=roc_auc_score(y_lb, y_pred_lb, average=\"macro\")\n",
    "    Score_view(score_train,score_test,cm_df,cr,accu,ras)\n",
    "        \n",
    "    if pred_un==True:\n",
    "        unseen_pred=grid.predict(un_X)\n",
    "        k=0\n",
    "        for i,n in enumerate(un_y.cat.tolist()):\n",
    "\n",
    "            if not n==unseen_pred[i]:\n",
    "                k=k+1\n",
    "        print('----------------------')\n",
    "        print('Unseen Data evaluation')\n",
    "        print('----------------------')\n",
    "        print('')        \n",
    "        print('Total classified unseen image count: ',len(un_y))\n",
    "        print('Miss classified unseen image count: ',k)\n",
    "        print('% of miss classified unseen images: ',(k/len(un_y))*100,'%')\n",
    "        print('')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score board function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to print scores\n",
    "#Inputs:\n",
    "    # score_train - train score\n",
    "    # score_test -test score\n",
    "    # cm_df - confusion matrix dataframe\n",
    "    # cr - classification report value\n",
    "    # accu - accuracy value\n",
    "    # ras  - ROCAUC value\n",
    "score_train,score_test,cm_df,cr,accu,ras=[0,0,0,0,0,0]\n",
    "def Score_view(score_train=score_train,score_test=score_test,cm_df=cm_df,cr=cr,accu=accu,ras=ras):\n",
    "    print(\"\")\n",
    "    print('Score our model on the training set: ',score_train)\n",
    "    print(\"\")\n",
    "    print('Score our model on the testing set: ',score_test)\n",
    "    print('')\n",
    "    print('** Confusion matrix **')\n",
    "    print('----------------------')\n",
    "    print(cm_df)\n",
    "    print('')\n",
    "    print('** Classification Report **')\n",
    "    print('---------------------------')\n",
    "    print(cr)\n",
    "    print('')\n",
    "    print('---------------------')\n",
    "    print('| Accuracy : {}% |'.format(accu))\n",
    "    print('---------------------')\n",
    "    print('')\n",
    "    print('---------------------')\n",
    "    print('| ROC Score : {}% |'.format(round(ras*100,3)))\n",
    "    print('---------------------')\n",
    "    print('')\n",
    "    print('===========================================================================')\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beep Beep function :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to make a Beep Beep Beep sound if needed\n",
    "def beep_beep():\n",
    "    import winsound\n",
    "    frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "    duration = 100  # Set Duration To 1000 ms == 1 second\n",
    "    winsound.Beep(frequency, duration)\n",
    "    winsound.Beep(frequency, duration)\n",
    "    winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Train dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path of all labeled images list\n",
    "c1path='./data/C1.csv'\n",
    "c2path='./data/C2.csv'\n",
    "c3path='./data/C3.csv'\n",
    "c4path='./data/C4.csv'\n",
    "c5path='./data/C5.csv'\n",
    "c6path='./data/C6.csv'\n",
    "c7path='./data/C7.csv'\n",
    "c8path='./data/C8.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat all labeled image list\n",
    "df=pd.read_csv(c1path)\n",
    "dftemp=pd.read_csv(c2path)\n",
    "df = pd.concat([df, dftemp],ignore_index=True)\n",
    "dftemp=pd.read_csv(c3path)\n",
    "df = pd.concat([df, dftemp], ignore_index=True)\n",
    "dftemp=pd.read_csv(c4path)\n",
    "df = pd.concat([df, dftemp], ignore_index=True)\n",
    "dftemp=pd.read_csv(c5path)\n",
    "df = pd.concat([df, dftemp], ignore_index=True)\n",
    "dftemp=pd.read_csv(c6path)\n",
    "df = pd.concat([df, dftemp], ignore_index=True)\n",
    "dftemp=pd.read_csv(c7path)\n",
    "df = pd.concat([df, dftemp], ignore_index=True)\n",
    "dftemp=pd.read_csv(c8path)\n",
    "df = pd.concat([df, dftemp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cat.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lbpene           0\n",
       "lbpent       18853\n",
       "dissim           0\n",
       "homogen          0\n",
       "ener             0\n",
       "corre            0\n",
       "gabor_ene        0\n",
       "gabor_ent    22924\n",
       "cat              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#any missing data fill with 0\n",
    "df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lbpene</th>\n",
       "      <th>lbpent</th>\n",
       "      <th>dissim</th>\n",
       "      <th>homogen</th>\n",
       "      <th>ener</th>\n",
       "      <th>corre</th>\n",
       "      <th>gabor_ene</th>\n",
       "      <th>gabor_ent</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.918707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037872</td>\n",
       "      <td>0.981065</td>\n",
       "      <td>0.881493</td>\n",
       "      <td>0.816120</td>\n",
       "      <td>0.998978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.919737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036982</td>\n",
       "      <td>0.981511</td>\n",
       "      <td>0.886730</td>\n",
       "      <td>0.809414</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.915414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040689</td>\n",
       "      <td>0.979658</td>\n",
       "      <td>0.877484</td>\n",
       "      <td>0.806211</td>\n",
       "      <td>0.998642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.916980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039246</td>\n",
       "      <td>0.980380</td>\n",
       "      <td>0.881061</td>\n",
       "      <td>0.806787</td>\n",
       "      <td>0.999037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.917559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037253</td>\n",
       "      <td>0.981374</td>\n",
       "      <td>0.884812</td>\n",
       "      <td>0.812264</td>\n",
       "      <td>0.998662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lbpene  lbpent    dissim   homogen      ener     corre  gabor_ene  \\\n",
       "0  0.918707     0.0  0.037872  0.981065  0.881493  0.816120   0.998978   \n",
       "1  0.919737     0.0  0.036982  0.981511  0.886730  0.809414   0.999009   \n",
       "2  0.915414     0.0  0.040689  0.979658  0.877484  0.806211   0.998642   \n",
       "3  0.916980     0.0  0.039246  0.980380  0.881061  0.806787   0.999037   \n",
       "4  0.917559     0.0  0.037253  0.981374  0.884812  0.812264   0.998662   \n",
       "\n",
       "   gabor_ent  cat  \n",
       "0        0.0    1  \n",
       "1        0.0    1  \n",
       "2        0.0    1  \n",
       "3        0.0    1  \n",
       "4        0.0    1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lbpene</th>\n",
       "      <th>lbpent</th>\n",
       "      <th>dissim</th>\n",
       "      <th>homogen</th>\n",
       "      <th>ener</th>\n",
       "      <th>corre</th>\n",
       "      <th>gabor_ene</th>\n",
       "      <th>gabor_ent</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>0.752845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241025</td>\n",
       "      <td>0.904453</td>\n",
       "      <td>0.740310</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.728165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>0.770907</td>\n",
       "      <td>0.737184</td>\n",
       "      <td>0.186435</td>\n",
       "      <td>0.919888</td>\n",
       "      <td>0.711262</td>\n",
       "      <td>0.999753</td>\n",
       "      <td>0.687355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>0.774448</td>\n",
       "      <td>0.730525</td>\n",
       "      <td>0.199259</td>\n",
       "      <td>0.919788</td>\n",
       "      <td>0.750928</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>0.751846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>0.776562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208074</td>\n",
       "      <td>0.917729</td>\n",
       "      <td>0.736606</td>\n",
       "      <td>0.999569</td>\n",
       "      <td>0.732650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>0.779119</td>\n",
       "      <td>0.720844</td>\n",
       "      <td>0.184394</td>\n",
       "      <td>0.920184</td>\n",
       "      <td>0.730101</td>\n",
       "      <td>0.999705</td>\n",
       "      <td>0.711800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lbpene    lbpent    dissim   homogen      ener     corre  gabor_ene  \\\n",
       "23995  0.752845  0.000000  0.241025  0.904453  0.740310  0.999451   0.728165   \n",
       "23996  0.770907  0.737184  0.186435  0.919888  0.711262  0.999753   0.687355   \n",
       "23997  0.774448  0.730525  0.199259  0.919788  0.750928  0.999579   0.751846   \n",
       "23998  0.776562  0.000000  0.208074  0.917729  0.736606  0.999569   0.732650   \n",
       "23999  0.779119  0.720844  0.184394  0.920184  0.730101  0.999705   0.711800   \n",
       "\n",
       "       gabor_ent  cat  \n",
       "23995        0.0    8  \n",
       "23996        0.0    8  \n",
       "23997        0.0    8  \n",
       "23998        0.0    8  \n",
       "23999        0.0    8  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select X and y then split train and test data\n",
    "X=df.drop(columns=['cat'])\n",
    "y=df.drop(columns=['lbpene','lbpent','dissim','homogen','ener','corre','gabor_ene','gabor_ent'])\n",
    "\n",
    "X_st_train, X_st_test, y_st_train, y_st_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search, Model training and View scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################\n",
      "      Logistic Regression \n",
      "################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thelee\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters of classifier from GridSearchCV\n",
      "-----------------------------------------------------------\n",
      "\n",
      "model__C: 1000\n",
      "model__multi_class: 'multinomial'\n",
      "model__penalty: 'l1'\n",
      "model__solver: 'saga'\n",
      "\n",
      "Score our model on the training set:  0.9708928571428571\n",
      "\n",
      "Score our model on the testing set:  0.9705555555555555\n",
      "\n",
      "** Confusion matrix **\n",
      "----------------------\n",
      "           Predicted C1  Predicted C2  Predicted C3  Predicted C4  \\\n",
      "Actual C1           895             0             5             0   \n",
      "Actual C2             0           897             3             0   \n",
      "Actual C3            29             0           871             0   \n",
      "Actual C4            57             0             0           822   \n",
      "Actual C5             0             0             0             0   \n",
      "Actual C6             0             0             0            97   \n",
      "Actual C7             0             0             0             0   \n",
      "Actual C8             0             0             0             0   \n",
      "\n",
      "           Predicted C5  Predicted C6  Actual C7  Actual C8  \n",
      "Actual C1             0             0          0          0  \n",
      "Actual C2             0             0          0          0  \n",
      "Actual C3             0             0          0          0  \n",
      "Actual C4             0            21          0          0  \n",
      "Actual C5           900             0          0          0  \n",
      "Actual C6             0           803          0          0  \n",
      "Actual C7             0             0        900          0  \n",
      "Actual C8             0             0          0        900  \n",
      "\n",
      "** Classification Report **\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.99      0.95       900\n",
      "           2       1.00      1.00      1.00       900\n",
      "           3       0.99      0.97      0.98       900\n",
      "           4       0.89      0.91      0.90       900\n",
      "           5       1.00      1.00      1.00       900\n",
      "           6       0.97      0.89      0.93       900\n",
      "           7       1.00      1.00      1.00       900\n",
      "           8       1.00      1.00      1.00       900\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      7200\n",
      "   macro avg       0.97      0.97      0.97      7200\n",
      "weighted avg       0.97      0.97      0.97      7200\n",
      "\n",
      "\n",
      "---------------------\n",
      "| Accuracy : 97.06% |\n",
      "---------------------\n",
      "\n",
      "---------------------\n",
      "| ROC Score : 98.317% |\n",
      "---------------------\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thelee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression training and grid search\n",
    "#parameter range to be searched for best parameters\n",
    "params={'model__C':[0.01,1,10,100,1000],\n",
    "        'model__penalty':['l1','l2'],\n",
    "         'model__multi_class':['multinomial'],\n",
    "    'model__solver':['saga']}\n",
    "\n",
    "#'LR' - for Logistic Regression\n",
    "estm='LR'\n",
    "Models_func(X_train=X_st_train,X_test=X_st_test,y_train=y_st_train,y_test=y_st_test,params=params,estm=estm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################\n",
      "      KNN Classifier \n",
      "################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thelee\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters of classifier from GridSearchCV\n",
      "-----------------------------------------------------------\n",
      "\n",
      "model__leaf_size: 10\n",
      "model__n_neighbors: 3\n",
      "\n",
      "Score our model on the training set:  0.9986904761904762\n",
      "\n",
      "Score our model on the testing set:  0.9965277777777778\n",
      "\n",
      "** Confusion matrix **\n",
      "----------------------\n",
      "           Predicted C1  Predicted C2  Predicted C3  Predicted C4  \\\n",
      "Actual C1           899             0             1             0   \n",
      "Actual C2             0           899             1             0   \n",
      "Actual C3             2             0           898             0   \n",
      "Actual C4             3             0             0           893   \n",
      "Actual C5             0             0             0             0   \n",
      "Actual C6             0             0             0            14   \n",
      "Actual C7             0             0             0             0   \n",
      "Actual C8             0             0             0             0   \n",
      "\n",
      "           Predicted C5  Predicted C6  Actual C7  Actual C8  \n",
      "Actual C1             0             0          0          0  \n",
      "Actual C2             0             0          0          0  \n",
      "Actual C3             0             0          0          0  \n",
      "Actual C4             0             4          0          0  \n",
      "Actual C5           900             0          0          0  \n",
      "Actual C6             0           886          0          0  \n",
      "Actual C7             0             0        900          0  \n",
      "Actual C8             0             0          0        900  \n",
      "\n",
      "** Classification Report **\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      1.00      1.00       900\n",
      "           2       1.00      1.00      1.00       900\n",
      "           3       1.00      1.00      1.00       900\n",
      "           4       0.98      0.99      0.99       900\n",
      "           5       1.00      1.00      1.00       900\n",
      "           6       1.00      0.98      0.99       900\n",
      "           7       1.00      1.00      1.00       900\n",
      "           8       1.00      1.00      1.00       900\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      7200\n",
      "   macro avg       1.00      1.00      1.00      7200\n",
      "weighted avg       1.00      1.00      1.00      7200\n",
      "\n",
      "\n",
      "---------------------\n",
      "| Accuracy : 99.65% |\n",
      "---------------------\n",
      "\n",
      "---------------------\n",
      "| ROC Score : 99.802% |\n",
      "---------------------\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNeighbors Classifier training and grid search\n",
    "#parameter range to be searched for best parameters\n",
    "params={'model__leaf_size':[10,20,30,40],\n",
    "       'model__n_neighbors':[3,5,7,9,11]}\n",
    "\n",
    "#'KNN' - for KNeighbors\n",
    "estm='KNN'\n",
    "Models_func(X_train=X_st_train,X_test=X_st_test,y_train=y_st_train,y_test=y_st_test,params=params,estm=estm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################\n",
      "      Decision Tree Classifier \n",
      "################################################\n",
      "\n",
      "Best parameters of classifier from GridSearchCV\n",
      "-----------------------------------------------------------\n",
      "\n",
      "model__max_depth: 10\n",
      "model__min_samples_leaf: 5\n",
      "model__min_samples_split: 10\n",
      "\n",
      "Score our model on the training set:  0.998452380952381\n",
      "\n",
      "Score our model on the testing set:  0.9963888888888889\n",
      "\n",
      "** Confusion matrix **\n",
      "----------------------\n",
      "           Predicted C1  Predicted C2  Predicted C3  Predicted C4  \\\n",
      "Actual C1           898             0             0             2   \n",
      "Actual C2             0           900             0             0   \n",
      "Actual C3             0             0           900             0   \n",
      "Actual C4             2             0             0           894   \n",
      "Actual C5             0             0             0             0   \n",
      "Actual C6             0             0             0            18   \n",
      "Actual C7             0             0             0             0   \n",
      "Actual C8             0             0             0             0   \n",
      "\n",
      "           Predicted C5  Predicted C6  Actual C7  Actual C8  \n",
      "Actual C1             0             0          0          0  \n",
      "Actual C2             0             0          0          0  \n",
      "Actual C3             0             0          0          0  \n",
      "Actual C4             0             1          3          0  \n",
      "Actual C5           900             0          0          0  \n",
      "Actual C6             0           882          0          0  \n",
      "Actual C7             0             0        900          0  \n",
      "Actual C8             0             0          0        900  \n",
      "\n",
      "** Classification Report **\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       900\n",
      "           2       1.00      1.00      1.00       900\n",
      "           3       1.00      1.00      1.00       900\n",
      "           4       0.98      0.99      0.99       900\n",
      "           5       1.00      1.00      1.00       900\n",
      "           6       1.00      0.98      0.99       900\n",
      "           7       1.00      1.00      1.00       900\n",
      "           8       1.00      1.00      1.00       900\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      7200\n",
      "   macro avg       1.00      1.00      1.00      7200\n",
      "weighted avg       1.00      1.00      1.00      7200\n",
      "\n",
      "\n",
      "---------------------\n",
      "| Accuracy : 99.64% |\n",
      "---------------------\n",
      "\n",
      "---------------------\n",
      "| ROC Score : 99.794% |\n",
      "---------------------\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier training and grid search\n",
    "#parameter range to be searched for best parameters\n",
    "params={'model__max_depth': [3, 5, 7, 10],\n",
    "       'model__min_samples_split': [5, 10, 15, 20],\n",
    "       'model__min_samples_leaf': [2, 3, 4, 5, 6, 7]}\n",
    "\n",
    "#'DTC' - for Decision Tree Classifier\n",
    "estm='DTC'\n",
    "Models_func(X_train=X_st_train,X_test=X_st_test,y_train=y_st_train,y_test=y_st_test,params=params,estm=estm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################\n",
      "      Random Forrest Classifier \n",
      "################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thelee\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters of classifier from GridSearchCV\n",
      "-----------------------------------------------------------\n",
      "\n",
      "model__max_depth: None\n",
      "model__n_estimators: 200\n",
      "\n",
      "Score our model on the training set:  1.0\n",
      "\n",
      "Score our model on the testing set:  0.9988888888888889\n",
      "\n",
      "** Confusion matrix **\n",
      "----------------------\n",
      "           Predicted C1  Predicted C2  Predicted C3  Predicted C4  \\\n",
      "Actual C1           899             0             0             1   \n",
      "Actual C2             0           900             0             0   \n",
      "Actual C3             0             0           900             0   \n",
      "Actual C4             1             0             0           899   \n",
      "Actual C5             0             0             0             0   \n",
      "Actual C6             0             0             0             6   \n",
      "Actual C7             0             0             0             0   \n",
      "Actual C8             0             0             0             0   \n",
      "\n",
      "           Predicted C5  Predicted C6  Actual C7  Actual C8  \n",
      "Actual C1             0             0          0          0  \n",
      "Actual C2             0             0          0          0  \n",
      "Actual C3             0             0          0          0  \n",
      "Actual C4             0             0          0          0  \n",
      "Actual C5           900             0          0          0  \n",
      "Actual C6             0           894          0          0  \n",
      "Actual C7             0             0        900          0  \n",
      "Actual C8             0             0          0        900  \n",
      "\n",
      "** Classification Report **\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       900\n",
      "           2       1.00      1.00      1.00       900\n",
      "           3       1.00      1.00      1.00       900\n",
      "           4       0.99      1.00      1.00       900\n",
      "           5       1.00      1.00      1.00       900\n",
      "           6       1.00      0.99      1.00       900\n",
      "           7       1.00      1.00      1.00       900\n",
      "           8       1.00      1.00      1.00       900\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      7200\n",
      "   macro avg       1.00      1.00      1.00      7200\n",
      "weighted avg       1.00      1.00      1.00      7200\n",
      "\n",
      "\n",
      "---------------------\n",
      "| Accuracy : 99.89% |\n",
      "---------------------\n",
      "\n",
      "---------------------\n",
      "| ROC Score : 99.937% |\n",
      "---------------------\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier training and grid search\n",
    "#parameter range to be searched for best parameters\n",
    "params={'model__n_estimators': [100, 150, 200],\n",
    "       'model__max_depth': [None, 1, 2, 3, 4, 5]}\n",
    "\n",
    "#'RFC' - for Random Forest Classifier\n",
    "estm='RFC'\n",
    "Models_func(X_train=X_st_train,X_test=X_st_test,y_train=y_st_train,y_test=y_st_test,params=params,estm=estm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################\n",
      "      Extra Tree Classifier \n",
      "################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thelee\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters of classifier from GridSearchCV\n",
      "-----------------------------------------------------------\n",
      "\n",
      "model__max_depth: None\n",
      "model__n_estimators: 100\n",
      "\n",
      "Score our model on the training set:  1.0\n",
      "\n",
      "Score our model on the testing set:  0.9990277777777777\n",
      "\n",
      "** Confusion matrix **\n",
      "----------------------\n",
      "           Predicted C1  Predicted C2  Predicted C3  Predicted C4  \\\n",
      "Actual C1           899             0             0             1   \n",
      "Actual C2             0           900             0             0   \n",
      "Actual C3             0             0           900             0   \n",
      "Actual C4             1             0             0           899   \n",
      "Actual C5             0             0             0             0   \n",
      "Actual C6             0             0             0             5   \n",
      "Actual C7             0             0             0             0   \n",
      "Actual C8             0             0             0             0   \n",
      "\n",
      "           Predicted C5  Predicted C6  Actual C7  Actual C8  \n",
      "Actual C1             0             0          0          0  \n",
      "Actual C2             0             0          0          0  \n",
      "Actual C3             0             0          0          0  \n",
      "Actual C4             0             0          0          0  \n",
      "Actual C5           900             0          0          0  \n",
      "Actual C6             0           895          0          0  \n",
      "Actual C7             0             0        900          0  \n",
      "Actual C8             0             0          0        900  \n",
      "\n",
      "** Classification Report **\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       900\n",
      "           2       1.00      1.00      1.00       900\n",
      "           3       1.00      1.00      1.00       900\n",
      "           4       0.99      1.00      1.00       900\n",
      "           5       1.00      1.00      1.00       900\n",
      "           6       1.00      0.99      1.00       900\n",
      "           7       1.00      1.00      1.00       900\n",
      "           8       1.00      1.00      1.00       900\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      7200\n",
      "   macro avg       1.00      1.00      1.00      7200\n",
      "weighted avg       1.00      1.00      1.00      7200\n",
      "\n",
      "\n",
      "---------------------\n",
      "| Accuracy : 99.9% |\n",
      "---------------------\n",
      "\n",
      "---------------------\n",
      "| ROC Score : 99.944% |\n",
      "---------------------\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Classifier training and grid search\n",
    "#parameter range to be searched for best parameters\n",
    "params={'model__n_estimators': [100, 150, 200],\n",
    "       'model__max_depth': [None, 1, 2, 3, 4, 5]}\n",
    "\n",
    "#'ETC - for Extra Trees Classifier\n",
    "estm='ETC'\n",
    "Models_func(X_train=X_st_train,X_test=X_st_test,y_train=y_st_train,y_test=y_st_test,params=params,estm=estm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################\n",
      "      Support Vector Machine \n",
      "################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thelee\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters of classifier from GridSearchCV\n",
      "-----------------------------------------------------------\n",
      "\n",
      "model__C: 100.0\n",
      "model__gamma: 21.54434690031882\n",
      "model__kernel: 'rbf'\n",
      "\n",
      "Score our model on the training set:  0.9994047619047619\n",
      "\n",
      "Score our model on the testing set:  0.9973611111111111\n",
      "\n",
      "** Confusion matrix **\n",
      "----------------------\n",
      "           Predicted C1  Predicted C2  Predicted C3  Predicted C4  \\\n",
      "Actual C1           900             0             0             0   \n",
      "Actual C2             0           899             1             0   \n",
      "Actual C3             0             0           899             0   \n",
      "Actual C4             1             0             0           895   \n",
      "Actual C5             0             0             0             0   \n",
      "Actual C6             0             0             0            12   \n",
      "Actual C7             0             0             0             0   \n",
      "Actual C8             0             0             0             0   \n",
      "\n",
      "           Predicted C5  Predicted C6  Actual C7  Actual C8  \n",
      "Actual C1             0             0          0          0  \n",
      "Actual C2             0             0          0          0  \n",
      "Actual C3             0             0          0          1  \n",
      "Actual C4             0             4          0          0  \n",
      "Actual C5           900             0          0          0  \n",
      "Actual C6             0           888          0          0  \n",
      "Actual C7             0             0        900          0  \n",
      "Actual C8             0             0          0        900  \n",
      "\n",
      "** Classification Report **\n",
      "---------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       900\n",
      "           2       1.00      1.00      1.00       900\n",
      "           3       1.00      1.00      1.00       900\n",
      "           4       0.99      0.99      0.99       900\n",
      "           5       1.00      1.00      1.00       900\n",
      "           6       1.00      0.99      0.99       900\n",
      "           7       1.00      1.00      1.00       900\n",
      "           8       1.00      1.00      1.00       900\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      7200\n",
      "   macro avg       1.00      1.00      1.00      7200\n",
      "weighted avg       1.00      1.00      1.00      7200\n",
      "\n",
      "\n",
      "---------------------\n",
      "| Accuracy : 99.74% |\n",
      "---------------------\n",
      "\n",
      "---------------------\n",
      "| ROC Score : 99.849% |\n",
      "---------------------\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines training and grid search\n",
    "#parameter range to be searched for best parameters\n",
    "params={'model__gamma' : np.logspace(-1, 2, 10),\n",
    "       'model__C' : np.logspace(-1, 2, 10),\n",
    "       'model__kernel' : ['rbf','linear','sigmoid']}\n",
    "\n",
    "#SVM - for Support Vector Machines\n",
    "estm='SVM'\n",
    "Models_func(X_train=X_st_train,X_test=X_st_test,y_train=y_st_train,y_test=y_st_test,params=params,estm=estm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beep and alert when done\n",
    "beep_beep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating using a set of unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path on unseen data image list\n",
    "c1path='./data/unseenC1.csv'\n",
    "c2path='./data/unseenC2.csv'\n",
    "c3path='./data/unseenC3.csv'\n",
    "c4path='./data/unseenC4.csv'\n",
    "c5path='./data/unseenC5.csv'\n",
    "c6path='./data/unseenC6.csv'\n",
    "c7path='./data/unseenC7.csv'\n",
    "c8path='./data/unseenC8.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lbpene  lbpent    dissim   homogen      ener     corre  gabor_ene  \\\n",
      "0  0.916520     NaN  0.039602  0.980203  0.879294  0.808537   0.998985   \n",
      "1  0.917885     NaN  0.037981  0.981010  0.882821  0.812165   0.998796   \n",
      "2  0.917844     NaN  0.039431  0.980285  0.882734  0.802900   0.998664   \n",
      "3  0.917760     NaN  0.038532  0.980734  0.882066  0.809530   0.998894   \n",
      "4  0.917855     NaN  0.038371  0.980816  0.878643  0.816948   0.998612   \n",
      "\n",
      "   gabor_ent  cat  \n",
      "0        NaN    1  \n",
      "1        NaN    1  \n",
      "2        NaN    1  \n",
      "3        NaN    1  \n",
      "4        NaN    1  \n",
      "(1790, 9)\n",
      "[1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "# concat all unseen image list\n",
    "un_df=pd.read_csv(c1path)\n",
    "un_dftemp=pd.read_csv(c2path)\n",
    "un_df = pd.concat([un_df, un_dftemp], ignore_index=True)\n",
    "un_dftemp=pd.read_csv(c3path)\n",
    "un_df = pd.concat([un_df, un_dftemp], ignore_index=True)\n",
    "un_dftemp=pd.read_csv(c4path)\n",
    "un_df = pd.concat([un_df, un_dftemp], ignore_index=True)\n",
    "un_dftemp=pd.read_csv(c5path)\n",
    "un_df = pd.concat([un_df, un_dftemp], ignore_index=True)\n",
    "un_dftemp=pd.read_csv(c6path)\n",
    "un_df = pd.concat([un_df, un_dftemp], ignore_index=True)\n",
    "un_dftemp=pd.read_csv(c7path)\n",
    "un_df = pd.concat([un_df, un_dftemp], ignore_index=True)\n",
    "un_dftemp=pd.read_csv(c8path)\n",
    "un_df = pd.concat([un_df, un_dftemp], ignore_index=True)\n",
    "print(un_df.head())\n",
    "print(un_df.shape)\n",
    "print(un_df.cat.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lbpene          0\n",
       "lbpent       1767\n",
       "dissim          0\n",
       "homogen         0\n",
       "ener            0\n",
       "corre           0\n",
       "gabor_ene       0\n",
       "gabor_ent    1752\n",
       "cat             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all null values with 0\n",
    "un_df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select X and y\n",
    "unseen_X=un_df.drop(columns=['cat'])\n",
    "unseen_y=un_df.drop(columns=['lbpene','lbpent','dissim','homogen','ener','corre','gabor_ene','gabor_ent'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to load model, classify and output confusion matrix and yield.\n",
    "def predict_unseen(unseen_X=unseen_X,unseen_y=unseen_y,estm='LR'):\n",
    "    with open ('./models/'+estm+'_model.plk','rb') as f:\n",
    "        model=pickle.load(f)\n",
    "    predict=model.predict(unseen_X)\n",
    "    \n",
    "    k=0\n",
    "    yld=0\n",
    "    for i,n in enumerate(unseen_y.cat):\n",
    "        if not n==predict[i]:\n",
    "                k=k+1\n",
    "        if n==1 and predict[i]==1:\n",
    "            yld=yld+1\n",
    "        \n",
    "    print('----------------------')\n",
    "    print('Unseen Data evaluation')\n",
    "    print('----------------------')\n",
    "    print('')        \n",
    "    print('Total classified unseen image count: ',len(unseen_y))\n",
    "    print('Miss classified unseen image count: ',k)\n",
    "    print('% of miss classified unseen images: ',(k/len(unseen_y))*100,'%')\n",
    "    print('')\n",
    "    print('Batch Yield %:', (yld/len(unseen_y)*100),'%')\n",
    "    print('')\n",
    "    cdf=pd.DataFrame(predict,columns=['predicted'])\n",
    "    cdf = pd.concat([cdf, unseen_y.cat],axis=1)\n",
    "    print('Unseen data prediction confusion matrix')\n",
    "    confusion_matrix = pd.crosstab(cdf['cat'], cdf['predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    cm=pd.DataFrame(confusion_matrix)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "Unseen Data evaluation\n",
      "----------------------\n",
      "\n",
      "Total classified unseen image count:  1790\n",
      "Miss classified unseen image count:  14\n",
      "% of miss classified unseen images:  0.782122905027933 %\n",
      "\n",
      "Batch Yield %: 72.40223463687151 %\n",
      "\n",
      "Unseen data prediction confusion matrix\n",
      "Predicted     1    2   3   4   5  6    7   8\n",
      "Actual                                      \n",
      "1          1296    0   4   0   0  0    0   0\n",
      "2             0  199   1   0   0  0    0   0\n",
      "3             5    0  95   0   0  0    0   0\n",
      "4             3    0   0  52   0  0    0   0\n",
      "5             0    0   0   0  10  0    0   0\n",
      "6             0    0   0   1   0  9    0   0\n",
      "7             0    0   0   0   0  0  100   0\n",
      "8             0    0   0   0   0  0    0  15\n"
     ]
    }
   ],
   "source": [
    "predict_unseen(unseen_X=unseen_X,estm='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of defective images have been classified as good and some good images are classified as defective. Miss classification at 0.79%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors Classifier validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "Unseen Data evaluation\n",
      "----------------------\n",
      "\n",
      "Total classified unseen image count:  1790\n",
      "Miss classified unseen image count:  2\n",
      "% of miss classified unseen images:  0.11173184357541899 %\n",
      "\n",
      "Batch Yield %: 72.56983240223464 %\n",
      "\n",
      "Unseen data prediction confusion matrix\n",
      "Predicted     1    2    3   4   5   6    7   8\n",
      "Actual                                        \n",
      "1          1299    0    0   1   0   0    0   0\n",
      "2             0  199    1   0   0   0    0   0\n",
      "3             0    0  100   0   0   0    0   0\n",
      "4             0    0    0  55   0   0    0   0\n",
      "5             0    0    0   0  10   0    0   0\n",
      "6             0    0    0   0   0  10    0   0\n",
      "7             0    0    0   0   0   0  100   0\n",
      "8             0    0    0   0   0   0    0  15\n"
     ]
    }
   ],
   "source": [
    "predict_unseen(unseen_X=unseen_X,estm='KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No defective images have been classified as good and some good images classified as defective. Miss classification at 0.11%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "Unseen Data evaluation\n",
      "----------------------\n",
      "\n",
      "Total classified unseen image count:  1790\n",
      "Miss classified unseen image count:  3\n",
      "% of miss classified unseen images:  0.16759776536312848 %\n",
      "\n",
      "Batch Yield %: 72.45810055865923 %\n",
      "\n",
      "Unseen data prediction confusion matrix\n",
      "Predicted     1    2    3   4   5   6    7   8\n",
      "Actual                                        \n",
      "1          1297    0    0   3   0   0    0   0\n",
      "2             0  200    0   0   0   0    0   0\n",
      "3             0    0  100   0   0   0    0   0\n",
      "4             0    0    0  55   0   0    0   0\n",
      "5             0    0    0   0  10   0    0   0\n",
      "6             0    0    0   0   0  10    0   0\n",
      "7             0    0    0   0   0   0  100   0\n",
      "8             0    0    0   0   0   0    0  15\n"
     ]
    }
   ],
   "source": [
    "predict_unseen(unseen_X=unseen_X,estm='DTC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No defective images have been classified as good some good images are classified and defective. Miss classification at 0.16%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "Unseen Data evaluation\n",
      "----------------------\n",
      "\n",
      "Total classified unseen image count:  1790\n",
      "Miss classified unseen image count:  3\n",
      "% of miss classified unseen images:  0.16759776536312848 %\n",
      "\n",
      "Batch Yield %: 72.45810055865923 %\n",
      "\n",
      "Unseen data prediction confusion matrix\n",
      "Predicted     1    2    3   4   5   6    7   8\n",
      "Actual                                        \n",
      "1          1297    0    0   3   0   0    0   0\n",
      "2             0  200    0   0   0   0    0   0\n",
      "3             0    0  100   0   0   0    0   0\n",
      "4             0    0    0  55   0   0    0   0\n",
      "5             0    0    0   0  10   0    0   0\n",
      "6             0    0    0   0   0  10    0   0\n",
      "7             0    0    0   0   0   0  100   0\n",
      "8             0    0    0   0   0   0    0  15\n"
     ]
    }
   ],
   "source": [
    "predict_unseen(unseen_X=unseen_X,estm='RFC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No defective images have been classified as good some good images are classified and defective. Miss classification at 0.16%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classifier validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "Unseen Data evaluation\n",
      "----------------------\n",
      "\n",
      "Total classified unseen image count:  1790\n",
      "Miss classified unseen image count:  1\n",
      "% of miss classified unseen images:  0.055865921787709494 %\n",
      "\n",
      "Batch Yield %: 72.62569832402235 %\n",
      "\n",
      "Unseen data prediction confusion matrix\n",
      "Predicted     1    2    3   4   5   6    7   8\n",
      "Actual                                        \n",
      "1          1300    0    0   0   0   0    0   0\n",
      "2             0  199    1   0   0   0    0   0\n",
      "3             0    0  100   0   0   0    0   0\n",
      "4             0    0    0  55   0   0    0   0\n",
      "5             0    0    0   0  10   0    0   0\n",
      "6             0    0    0   0   0  10    0   0\n",
      "7             0    0    0   0   0   0  100   0\n",
      "8             0    0    0   0   0   0    0  15\n"
     ]
    }
   ],
   "source": [
    "predict_unseen(unseen_X=unseen_X,estm='ETC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No defective images have been classified as good, no good images are classified and defective. Miss classification at 0.05%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "Unseen Data evaluation\n",
      "----------------------\n",
      "\n",
      "Total classified unseen image count:  1790\n",
      "Miss classified unseen image count:  1\n",
      "% of miss classified unseen images:  0.055865921787709494 %\n",
      "\n",
      "Batch Yield %: 72.62569832402235 %\n",
      "\n",
      "Unseen data prediction confusion matrix\n",
      "Predicted     1    2    3   4   5   6    7   8\n",
      "Actual                                        \n",
      "1          1300    0    0   0   0   0    0   0\n",
      "2             0  199    1   0   0   0    0   0\n",
      "3             0    0  100   0   0   0    0   0\n",
      "4             0    0    0  55   0   0    0   0\n",
      "5             0    0    0   0  10   0    0   0\n",
      "6             0    0    0   0   0  10    0   0\n",
      "7             0    0    0   0   0   0  100   0\n",
      "8             0    0    0   0   0   0    0  15\n"
     ]
    }
   ],
   "source": [
    "predict_unseen(unseen_X=unseen_X,estm='SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No defective images have been classified as good, no good images are classified and defective. Miss classification at 0.05%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Based on train and test scores, accuracy and unseen data miss classification rate either Extra Trees Classifier and Support Vector Machine can be deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "62px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "263.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
